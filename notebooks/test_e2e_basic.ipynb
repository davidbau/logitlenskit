{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogitLensKit E2E Test: Basic Workflow\n",
    "\n",
    "This notebook tests the basic end-to-end workflow:\n",
    "1. Load a model\n",
    "2. Collect logit lens data\n",
    "3. Display the interactive widget\n",
    "\n",
    "Run with: `pytest --nbmake notebooks/test_e2e_basic.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Load environment variables\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add python/src to path for local development\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root / 'python' / 'src'))\n",
    "\n",
    "# Load .env.local\n",
    "env_path = project_root / '.env.local'\n",
    "if env_path.exists():\n",
    "    with open(env_path) as f:\n",
    "        for line in f:\n",
    "            if '=' in line and not line.startswith('#'):\n",
    "                key, val = line.strip().split('=', 1)\n",
    "                os.environ[key] = val.strip('\"').strip(\"'\")\n",
    "    print('Loaded .env.local')\n",
    "else:\n",
    "    print('Warning: .env.local not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Import logitlenskit\n",
    "from logitlenskit import (\n",
    "    collect_logit_lens_topk_efficient,\n",
    "    show_logit_lens,\n",
    "    detect_model_type,\n",
    "    MODEL_CONFIGS,\n",
    ")\n",
    "\n",
    "print('Imports successful')\n",
    "print(f'Supported model types: {list(MODEL_CONFIGS.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Load GPT-2 model (local, no NDIF required)\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "model = LanguageModel('openai-community/gpt2', device_map='auto')\n",
    "print(f'Loaded model: {model.config.model_type}')\n",
    "\n",
    "# Verify detection\n",
    "detected = detect_model_type(model)\n",
    "assert detected == 'gpt2', f'Expected gpt2, got {detected}'\n",
    "print(f'Model type detected: {detected}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Collect logit lens data (local execution)\n",
    "prompt = 'The quick brown fox'\n",
    "\n",
    "data = collect_logit_lens_topk_efficient(\n",
    "    prompt,\n",
    "    model,\n",
    "    top_k=5,\n",
    "    track_across_layers=True,\n",
    "    remote=False,  # Local execution\n",
    ")\n",
    "\n",
    "print(f'Tokens: {data[\"tokens\"]}')\n",
    "print(f'Layers analyzed: {len(data[\"layers\"])}')\n",
    "print(f'Top indices shape: {data[\"top_indices\"].shape}')\n",
    "print(f'Tracked tokens per position: {[len(t) for t in data[\"tracked_indices\"]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Validate data structure\n",
    "assert 'tokens' in data, 'Missing tokens'\n",
    "assert 'layers' in data, 'Missing layers'\n",
    "assert 'top_indices' in data, 'Missing top_indices'\n",
    "assert 'top_probs' in data, 'Missing top_probs'\n",
    "assert 'tracked_indices' in data, 'Missing tracked_indices'\n",
    "assert 'tracked_probs' in data, 'Missing tracked_probs'\n",
    "\n",
    "# Shape checks\n",
    "n_layers = len(data['layers'])\n",
    "n_tokens = len(data['tokens'])\n",
    "k = 5\n",
    "\n",
    "assert data['top_indices'].shape == (n_layers, n_tokens, k), \\\n",
    "    f'top_indices shape mismatch: {data[\"top_indices\"].shape}'\n",
    "assert data['top_probs'].shape == (n_layers, n_tokens, k), \\\n",
    "    f'top_probs shape mismatch: {data[\"top_probs\"].shape}'\n",
    "assert len(data['tracked_indices']) == n_tokens, \\\n",
    "    f'tracked_indices length mismatch: {len(data[\"tracked_indices\"])}'\n",
    "assert len(data['tracked_probs']) == n_tokens, \\\n",
    "    f'tracked_probs length mismatch: {len(data[\"tracked_probs\"])}'\n",
    "\n",
    "print('Data structure validation passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 5: Format data for widget (v2 compact format)\nfrom logitlenskit import format_data_for_widget\n\nwidget_data = format_data_for_widget(data, model.tokenizer, model_name='openai-community/gpt2')\n\n# Check v2 format structure\nassert 'meta' in widget_data, 'Missing meta'\nassert 'layers' in widget_data, 'Missing layers'\nassert 'input' in widget_data, 'Missing input'\nassert 'tracked' in widget_data, 'Missing tracked'\nassert 'topk' in widget_data, 'Missing topk'\n\n# Check meta\nassert widget_data['meta']['version'] == 2, 'Version should be 2'\nassert 'timestamp' in widget_data['meta'], 'Missing timestamp'\nassert widget_data['meta']['model'] == 'openai-community/gpt2', 'Model name mismatch'\n\n# Check dimensions\nassert len(widget_data['input']) == n_tokens, f'input length mismatch'\nassert len(widget_data['tracked']) == n_tokens, f'tracked length mismatch'\nassert len(widget_data['topk']) == n_layers, f'topk layers mismatch'\nassert len(widget_data['topk'][0]) == n_tokens, f'topk positions mismatch'\n\n# Check tracked structure (dict of token -> trajectory)\nfirst_tracked = widget_data['tracked'][0]\nassert isinstance(first_tracked, dict), 'tracked[0] should be dict'\nfirst_token = list(first_tracked.keys())[0]\nassert isinstance(first_tracked[first_token], list), 'trajectory should be list'\nassert len(first_tracked[first_token]) == n_layers, 'trajectory length should match layers'\n\n# Check topk structure (list of token strings)\nfirst_topk = widget_data['topk'][0][0]\nassert isinstance(first_topk, list), 'topk[layer][pos] should be list'\nassert all(isinstance(t, str) for t in first_topk), 'topk entries should be strings'\n\nprint(f'Widget data (v2): {len(widget_data[\"input\"])} tokens, {len(widget_data[\"layers\"])} layers')\nprint(f'Tracked tokens at pos 0: {len(widget_data[\"tracked\"][0])} unique tokens')\nprint(f'Sample topk at layer 0, pos 0: {widget_data[\"topk\"][0][0][:3]}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Display widget (visual verification)\n",
    "# This generates HTML that would render in a real Jupyter environment\n",
    "html = show_logit_lens(data, model.tokenizer, title='GPT-2: The quick brown fox')\n",
    "\n",
    "# Verify HTML was generated\n",
    "assert html is not None\n",
    "html_str = html.data\n",
    "assert 'LogitLensWidget' in html_str, 'Widget code not in HTML'\n",
    "assert 'GPT-2: The quick brown fox' in html_str, 'Title not in HTML'\n",
    "\n",
    "print(f'Generated HTML: {len(html_str)} characters')\n",
    "print('Widget HTML generation successful!')\n",
    "\n",
    "# Display (in real Jupyter this would show the interactive widget)\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 7: Layer subset\n",
    "layers_subset = [0, 3, 6, 9, 11]  # GPT-2 has 12 layers\n",
    "\n",
    "data_subset = collect_logit_lens_topk_efficient(\n",
    "    'Test',\n",
    "    model,\n",
    "    top_k=3,\n",
    "    layers=layers_subset,\n",
    "    remote=False,\n",
    ")\n",
    "\n",
    "assert data_subset['layers'] == layers_subset\n",
    "assert data_subset['top_indices'].shape[0] == len(layers_subset)\n",
    "\n",
    "print(f'Layer subset test passed: {layers_subset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('=' * 50)\n",
    "print('E2E Basic Test Summary')\n",
    "print('=' * 50)\n",
    "print('1. Imports: PASSED')\n",
    "print('2. Model loading: PASSED')\n",
    "print('3. Data collection: PASSED')\n",
    "print('4. Data validation: PASSED')\n",
    "print('5. Widget formatting: PASSED')\n",
    "print('6. HTML generation: PASSED')\n",
    "print('7. Layer subset: PASSED')\n",
    "print('=' * 50)\n",
    "print('All tests passed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}